{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      "name      183213 non-null object\n",
      "review    182702 non-null object\n",
      "rating    183531 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explorer les données\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Planetwise Flannel Wipes\n",
       "1                                Planetwise Wipe Pouch\n",
       "2                  Annas Dream Full Quilt with 2 Shams\n",
       "3    Stop Pacifier Sucking without tears with Thumb...\n",
       "4    Stop Pacifier Sucking without tears with Thumb...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews=products[products['name']=='Vulli Sophie the Giraffe Teether']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giraffe_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34313</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>He likes chewing on all the parts especially t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34314</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>My son loves this toy and fits great in the di...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34315</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>There really should be a large warning on the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34316</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>All the moms in my moms\\' group got Sophie for...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34317</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I was a little skeptical on whether Sophie was...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "34313  Vulli Sophie the Giraffe Teether   \n",
       "34314  Vulli Sophie the Giraffe Teether   \n",
       "34315  Vulli Sophie the Giraffe Teether   \n",
       "34316  Vulli Sophie the Giraffe Teether   \n",
       "34317  Vulli Sophie the Giraffe Teether   \n",
       "\n",
       "                                                  review  rating  \n",
       "34313  He likes chewing on all the parts especially t...       5  \n",
       "34314  My son loves this toy and fits great in the di...       5  \n",
       "34315  There really should be a large warning on the ...       1  \n",
       "34316  All the moms in my moms\\' group got Sophie for...       5  \n",
       "34317  I was a little skeptical on whether Sophie was...       5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giraffe_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12f0ccc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Build a sentiment classifier\n",
    "sns.countplot(x = 'rating' , data = products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define what's a positive and negative sentiment\n",
    "#ignore all 3* reviews\n",
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postitive sentiment=4* or 5*\n",
    "products['sentiment']=products['rating']>=4\n",
    "products['sentiment'] = products['sentiment'].apply(lambda x: 1 if x==True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['review'].isna()!=True] #Supprimer les données manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    it came earli and was not disappointed. i love...\n",
       "2    veri soft and comfort and warmer than it looks...\n",
       "3    this is a product well worth the purchase.  i ...\n",
       "4    all of my kid have cri non-stop when i tri to ...\n",
       "5    when the binki fairi came to our house, we did...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "products['stemmed'] = products['review'].map(lambda x: ' '.join([stemmer.stem(y) for y in x.split(' ')]))\n",
    "products.stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english', min_df=1, max_df=.5, ngram_range=(1,2))\n",
    "cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('condit pieces', 366366),\n",
       " ('darn adorable', 429005),\n",
       " ('babi neic', 127616),\n",
       " ('anyth carri', 89012),\n",
       " ('avoid bed', 118075),\n",
       " ('want toy', 1768263),\n",
       " ('shoulder pull', 1427278),\n",
       " ('thicker bottles', 1626496),\n",
       " ('torrenti downpoar', 1663849),\n",
       " ('cover nicer', 396529),\n",
       " ('walker sturdy', 1762942),\n",
       " ('head higher', 746116),\n",
       " ('replac complet', 1321713),\n",
       " ('oz jar', 1129361),\n",
       " ('lbs couldn', 885286),\n",
       " ('creat vaccin', 404850),\n",
       " ('usa price', 1726635),\n",
       " ('regular jammies', 1312298),\n",
       " ('suggest known', 1574226),\n",
       " ('shorten hid', 1426227)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate all the n-grams found in all documents\n",
    "from itertools import islice\n",
    "\n",
    "cvec.fit(products.stemmed)\n",
    "list(islice(cvec.vocabulary_.items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847324"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many total n-grams we have\n",
    "len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2102"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the vectorizer with new settings and check the new vocabulary length\n",
    "cvec = CountVectorizer(stop_words='english', min_df=.0025, max_df=.1, ngram_range=(1,2))\n",
    "cvec.fit(products.stemmed)\n",
    "len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (165975, 2102)\n",
      "nonzero count: 3693832\n",
      "sparsity: 1.06%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts = cvec.transform(products.stemmed)\n",
    "print('sparse matrix shape:', cvec_counts.shape)\n",
    "print('nonzero count:', cvec_counts.nnz)\n",
    "print('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrences</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>24936</td>\n",
       "      <td>stroller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>22415</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>21652</td>\n",
       "      <td>bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>19695</td>\n",
       "      <td>tri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>19646</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>19546</td>\n",
       "      <td>diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>19211</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>19050</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>19014</td>\n",
       "      <td>purchas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>18911</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      occurrences      term\n",
       "1748        24936  stroller\n",
       "288         22415       car\n",
       "151         21652       bag\n",
       "1875        19695       tri\n",
       "1820        19646     thing\n",
       "480         19546    diaper\n",
       "2089        19211      year\n",
       "1194        19050      nice\n",
       "1413        19014   purchas\n",
       "2005        18911      want"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let’s look at the top 10 most common terms\n",
    "occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\n",
    "counts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\n",
    "counts_df.sort_values(by='occurrences', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<165975x2102 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3693832 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformed_weights = transformer.fit_transform(cvec_counts)\n",
    "transformed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>stroller</td>\n",
       "      <td>0.014913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>car</td>\n",
       "      <td>0.014767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>bag</td>\n",
       "      <td>0.014478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>toy</td>\n",
       "      <td>0.014144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>year</td>\n",
       "      <td>0.013202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>diaper</td>\n",
       "      <td>0.012997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>purchas</td>\n",
       "      <td>0.012857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>got</td>\n",
       "      <td>0.012685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>cute</td>\n",
       "      <td>0.012654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term    weight\n",
       "1748  stroller  0.014913\n",
       "288        car  0.014767\n",
       "1194      nice  0.014593\n",
       "151        bag  0.014478\n",
       "1864       toy  0.014144\n",
       "2089      year  0.013202\n",
       "480     diaper  0.012997\n",
       "1413   purchas  0.012857\n",
       "761        got  0.012685\n",
       "439       cute  0.012654"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And we can take a look at the top 10 terms by average tf-idf weight:\n",
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>car</td>\n",
       "      <td>0.016715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.016288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>stroller</td>\n",
       "      <td>0.016249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>bag</td>\n",
       "      <td>0.015708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>toy</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>year</td>\n",
       "      <td>0.014876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>cute</td>\n",
       "      <td>0.014332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>diaper</td>\n",
       "      <td>0.014191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>soft</td>\n",
       "      <td>0.014155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>purchas</td>\n",
       "      <td>0.014066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term    weight\n",
       "228        car  0.016715\n",
       "915       nice  0.016288\n",
       "1369  stroller  0.016249\n",
       "121        bag  0.015708\n",
       "1469       toy  0.015625\n",
       "1619      year  0.014876\n",
       "365       cute  0.014332\n",
       "395     diaper  0.014191\n",
       "1290      soft  0.014155\n",
       "1092   purchas  0.014066"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And that about wraps it up for Tf-idf calculation. \n",
    "#As an example, you can jump straight to the end using the TfidfVectorizer class:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(min_df=.0025, max_df=.1, stop_words='english') #, ngram_range=ngramrange\n",
    "tvec_weights = tvec.fit_transform(products.stemmed.dropna())\n",
    "\n",
    "weights    = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = products['sentiment'] \n",
    "X = transformed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let training the sentiment classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.60      0.70      6568\n",
      "          1       0.93      0.98      0.95     34926\n",
      "\n",
      "avg / total       0.91      0.92      0.91     41494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the learned model to understand sentiment for giraffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717, 2102)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gi = products[products['name']=='Vulli Sophie the Giraffe Teether']\n",
    "gi_counts = cvec.transform(gi.stemmed)\n",
    "gi_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "X_GIR = transformer.fit_transform(gi_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_GIR)[1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gi['sentiment'][1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.85397224e-04,   9.99514603e-01],\n",
       "       [  6.05545077e-01,   3.94454923e-01],\n",
       "       [  1.31498088e-02,   9.86850191e-01],\n",
       "       [  5.94265647e-02,   9.40573435e-01],\n",
       "       [  1.77913269e-02,   9.82208673e-01],\n",
       "       [  1.60179176e-01,   8.39820824e-01],\n",
       "       [  6.16498452e-02,   9.38350155e-01],\n",
       "       [  9.97224131e-02,   9.00277587e-01],\n",
       "       [  2.26451538e-02,   9.77354846e-01],\n",
       "       [  2.54179866e-02,   9.74582013e-01],\n",
       "       [  4.98072131e-01,   5.01927869e-01],\n",
       "       [  3.38061434e-01,   6.61938566e-01],\n",
       "       [  1.42991744e-02,   9.85700826e-01],\n",
       "       [  6.03177688e-02,   9.39682231e-01],\n",
       "       [  6.91226109e-03,   9.93087739e-01],\n",
       "       [  5.11734637e-03,   9.94882654e-01],\n",
       "       [  2.68796339e-02,   9.73120366e-01],\n",
       "       [  2.17662612e-02,   9.78233739e-01],\n",
       "       [  1.10088088e-01,   8.89911912e-01],\n",
       "       [  6.71908797e-02,   9.32809120e-01],\n",
       "       [  2.94194213e-01,   7.05805787e-01],\n",
       "       [  8.85470128e-03,   9.91145299e-01],\n",
       "       [  3.60096113e-02,   9.63990389e-01],\n",
       "       [  2.09819100e-02,   9.79018090e-01],\n",
       "       [  9.60431767e-03,   9.90395682e-01],\n",
       "       [  1.64596326e-02,   9.83540367e-01],\n",
       "       [  2.31585947e-01,   7.68414053e-01],\n",
       "       [  1.49739847e-01,   8.50260153e-01],\n",
       "       [  1.12413703e-01,   8.87586297e-01]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_GIR)[1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29x2102 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 531 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_GIR[1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', \n",
    "                  'terrible', 'awful', 'wow', 'hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>it came earli and was not disappointed. i love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>veri soft and comfort and warmer than it looks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>this is a product well worth the purchase.  i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>all of my kid have cri non-stop when i tri to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>when the binki fairi came to our house, we did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "1  it came early and was not disappointed. i love...       5          1   \n",
       "2  Very soft and comfortable and warmer than it l...       5          1   \n",
       "3  This is a product well worth the purchase.  I ...       5          1   \n",
       "4  All of my kids have cried non-stop when I trie...       5          1   \n",
       "5  When the Binky Fairy came to our house, we did...       5          1   \n",
       "\n",
       "                                             stemmed  \n",
       "1  it came earli and was not disappointed. i love...  \n",
       "2  veri soft and comfort and warmer than it looks...  \n",
       "3  this is a product well worth the purchase.  i ...  \n",
       "4  all of my kid have cri non-stop when i tri to ...  \n",
       "5  when the binki fairi came to our house, we did...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', \n",
    "                  'terrible', 'awful', 'wow', 'hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['awesome']   = products['stemmed'].apply(lambda x : 1 if 'awesome' in x else 0)\n",
    "products['great']     = products['stemmed'].apply(lambda x : 1 if 'great' in x else 0)\n",
    "products['fantastic'] = products['stemmed'].apply(lambda x : 1 if 'fantastic' in x else 0)\n",
    "products['amazing']   = products['stemmed'].apply(lambda x : 1 if 'amazing' in x else 0)\n",
    "products['love']      = products['stemmed'].apply(lambda x : 1 if 'love' in x else 0)\n",
    "products['horrible']  = products['stemmed'].apply(lambda x : 1 if 'horrible' in x else 0)\n",
    "products['bad']       = products['stemmed'].apply(lambda x : 1 if 'bad' in x else 0)\n",
    "products['terrible']  = products['stemmed'].apply(lambda x : 1 if 'terrible' in x else 0)\n",
    "products['awful']     = products['stemmed'].apply(lambda x : 1 if 'awful' in x else 0)\n",
    "products['wow']       = products['stemmed'].apply(lambda x : 1 if 'wow' in x else 0)\n",
    "products['hate']      = products['stemmed'].apply(lambda x : 1 if 'hate' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(products[selected_words])\n",
    "y = products['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.03      0.06      6619\n",
      "          1       0.84      1.00      0.91     34875\n",
      "\n",
      "avg / total       0.83      0.84      0.78     41494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
